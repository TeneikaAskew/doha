name: Download DOHA Case PDFs

on:
  schedule:
    # Run daily at 2 AM UTC (9 PM EST / 6 PM PST)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      max_cases:
        description: 'Maximum number of cases to process (leave empty for all new cases)'
        required: false
        default: ''

jobs:
  download-pdfs:
    runs-on: ubuntu-latest
    timeout-minutes: 200  # 3.3 hour timeout for link scraping + PDF downloads + index updates

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Need full history to properly track changes
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install chromium
          playwright install-deps chromium

      - name: Scrape latest case links
        run: |
          echo "Collecting latest case links from DOHA website..."
          python run_full_scrape.py

          # Count total links collected
          if [ -f doha_full_scrape/all_case_links.json ]; then
            LINK_COUNT=$(python -c "import json; print(len(json.load(open('doha_full_scrape/all_case_links.json'))))")
            echo "Collected $LINK_COUNT total case links"
          fi

      - name: Run PDF download script
        env:
          # Set max cases from input or use empty for all new cases
          MAX_CASES: ${{ github.event.inputs.max_cases }}
        run: |
          # Build command with optional max-cases parameter
          CMD="python download_pdfs.py"
          if [ -n "$MAX_CASES" ]; then
            CMD="$CMD --max-cases $MAX_CASES"
          fi

          echo "Running: $CMD"
          $CMD

      - name: Update RAG index incrementally
        run: |
          echo "Updating RAG index with new cases..."
          cd sead4_llm

          # Check if index exists
          if [ -d "../doha_index" ]; then
            echo "Existing index found - updating incrementally"
            python build_index.py --from-cases ../doha_parsed_cases/all_cases.parquet --output ../doha_index --update
          else
            echo "No existing index - building from scratch"
            python build_index.py --from-cases ../doha_parsed_cases/all_cases.parquet --output ../doha_index
          fi

          cd ..

      - name: Check for changes
        id: check_changes
        run: |
          # Check if there are any new or modified files (links + PDFs + index)
          git add doha_full_scrape/ doha_parsed_cases/hearing_pdfs/ doha_parsed_cases/appeal_pdfs/ doha_parsed_cases/all_cases.json doha_parsed_cases/all_cases.parquet doha_index/ || true

          if git diff --staged --quiet; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No new case links, PDFs, or index updates found"
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT

            # Count new PDFs
            NEW_FILES=$(git diff --staged --name-only | grep -c "\.pdf$" || echo "0")
            echo "new_pdfs=$NEW_FILES" >> $GITHUB_OUTPUT

            # Count new/modified link files
            NEW_LINKS=$(git diff --staged --name-only | grep -c "doha_full_scrape/.*\.json$" || echo "0")
            echo "new_links=$NEW_LINKS" >> $GITHUB_OUTPUT

            # Check if index was updated
            INDEX_UPDATED=$(git diff --staged --name-only | grep -c "doha_index/" || echo "0")
            echo "index_updated=$INDEX_UPDATED" >> $GITHUB_OUTPUT

            # Check if parquet was updated
            PARQUET_UPDATED=$(git diff --staged --name-only | grep -c "all_cases\.parquet" || echo "0")
            echo "parquet_updated=$PARQUET_UPDATED" >> $GITHUB_OUTPUT

            echo "Found $NEW_FILES new PDF(s), $NEW_LINKS updated link file(s), index updated: $INDEX_UPDATED, parquet updated: $PARQUET_UPDATED"
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Get counts
          NEW_PDFS="${{ steps.check_changes.outputs.new_pdfs }}"
          NEW_LINKS="${{ steps.check_changes.outputs.new_links }}"
          INDEX_UPDATED="${{ steps.check_changes.outputs.index_updated }}"
          PARQUET_UPDATED="${{ steps.check_changes.outputs.parquet_updated }}"

          # Build commit message
          COMMIT_MSG="Update DOHA case data and RAG index"
          COMMIT_BODY=""

          if [ "$NEW_LINKS" -gt 0 ]; then
            COMMIT_BODY="${COMMIT_BODY}Updated $NEW_LINKS case link file(s) from DOHA website"$'\n'
          fi

          if [ "$NEW_PDFS" -gt 0 ]; then
            COMMIT_BODY="${COMMIT_BODY}Downloaded $NEW_PDFS new case PDF(s)"$'\n'
          fi

          if [ "$PARQUET_UPDATED" -gt 0 ]; then
            COMMIT_BODY="${COMMIT_BODY}Updated parquet case database"$'\n'
          fi

          if [ "$INDEX_UPDATED" -gt 0 ]; then
            COMMIT_BODY="${COMMIT_BODY}Incrementally updated RAG index with new cases"$'\n'
          fi

          COMMIT_BODY="${COMMIT_BODY}"$'\n'"Automated update on $(date -u +%Y-%m-%d) at $(date -u +%H:%M:%S) UTC"

          # Create commit
          git commit -m "$COMMIT_MSG" -m "$COMMIT_BODY"

          git push

      - name: Create summary
        if: always()
        run: |
          echo "## DOHA Case Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ steps.check_changes.outputs.has_changes }}" == "true" ]; then
            NEW_LINKS="${{ steps.check_changes.outputs.new_links }}"
            NEW_PDFS="${{ steps.check_changes.outputs.new_pdfs }}"
            INDEX_UPDATED="${{ steps.check_changes.outputs.index_updated }}"
            PARQUET_UPDATED="${{ steps.check_changes.outputs.parquet_updated }}"

            if [ "$NEW_LINKS" -gt 0 ]; then
              echo "ðŸ”— **Updated $NEW_LINKS case link file(s)**" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$NEW_PDFS" -gt 0 ]; then
              echo "ðŸ“„ **Downloaded $NEW_PDFS new PDF(s)**" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$PARQUET_UPDATED" -gt 0 ]; then
              echo "ðŸ’¾ **Updated parquet case database**" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$INDEX_UPDATED" -gt 0 ]; then
              echo "ðŸ” **Updated RAG index incrementally**" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$NEW_LINKS" -eq 0 ] && [ "$NEW_PDFS" -eq 0 ] && [ "$INDEX_UPDATED" -eq 0 ]; then
              echo "â„¹ï¸ **Files updated but no new cases found**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "â„¹ï¸ **No new case links, PDFs, or index updates found**" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Run completed at $(date -u +%Y-%m-%d\ %H:%M:%S) UTC" >> $GITHUB_STEP_SUMMARY
